{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "\n",
    "def mostrar_tabla(dataframe: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Muestra un DataFrame de Pandas en formato tabular.\n",
    "\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): El DataFrame a mostrar.\n",
    "    \"\"\"\n",
    "    print(tabulate(dataframe, headers=dataframe.columns, tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_dependencia(nombre: str) -> str:\n",
    "    \"\"\"\n",
    "    Clasifica la dependencia en una de las categorías predefinidas.\n",
    "\n",
    "    Args:\n",
    "    - nombre: Nombre de la dependencia.\n",
    "\n",
    "    Returns:\n",
    "    - str: Categoría de la dependencia.\n",
    "    \"\"\"\n",
    "    categorias = {\n",
    "        'PREPARATORIA': ['PREPARATORIA', 'PREPA.'],\n",
    "        'FACULTAD': ['FACULTAD', 'FAC.'],\n",
    "        'HOSPITAL': ['HOSPITAL'],\n",
    "        'CENTRO': ['CENTRO', 'CTRO.', 'C.', 'INVESTIGAC'],\n",
    "        'ADMIN': ['SECRETARÍA', 'SECRETARIA', 'SRIA.', 'DIRECCIÓN',\n",
    "                    'DIRECCION', 'DEPARTAMENTO', 'DEPTO.', 'CONTRALORIA',\n",
    "                    'AUDITORIA', 'TESORERIA', 'ESCOLAR', 'ABOGACÍA', 'JUNTA',\n",
    "                    'RECTORIA', 'IMAGEN']\n",
    "    }\n",
    "\n",
    "    for categoria, palabras in categorias.items():\n",
    "        for palabra in palabras:\n",
    "            if palabra in nombre:\n",
    "                return categoria\n",
    "    return 'OTRO'\n",
    "\n",
    "def transformar_columna_fecha(df: pd.DataFrame,\n",
    "                                nombre_columna: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforma la columna de fecha en formato datetime.\n",
    "\n",
    "    Args:\n",
    "    - df: DataFrame de Pandas.\n",
    "    - nombre_columna: Nombre de la columna de fecha.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame con la columna de fecha transformada.\n",
    "    \"\"\"\n",
    "    df[nombre_columna] = pd.to_datetime(df[nombre_columna], format=\"%Y-%m\")\n",
    "    return df\n",
    "\n",
    "def agregar_tipos(df_crudo: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Añade las columnas 'Tipo' y 'Fecha' a la tabla.\n",
    "\n",
    "    Args:\n",
    "    - df_crudo (pd.DataFrame): La tabla a transformar.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: La tabla transformada\n",
    "    \"\"\"\n",
    "    df_crudo[\"Fecha\"] = pd.to_datetime(df_crudo[\"anio\"].map(str)+ \"-\"\n",
    "                        + raw_df[\"mes\"].map(str), format=\"%Y-%m\")\n",
    "    df_crudo[\"Tipo\"] = df_crudo[\"dependencia\"].apply(clasificar_dependencia)\n",
    "    df_transformado = df_crudo.drop(columns=['anio', 'mes'])\n",
    "    return df_transformado\n",
    "\n",
    "\n",
    "def analizar_por_dependencia(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Realiza un análisis de la información por departamento.\n",
    "\n",
    "    Args:\n",
    "    - df: DataFrame de Pandas con la información completa.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Tabla con el análisis realizado por departamento.\n",
    "    \"\"\"\n",
    "    df[\"Fecha\"] = pd.to_datetime(df[\"Fecha\"], format=\"%Y-%m-%d\")\n",
    "    df[\"anio\"] = df[\"Fecha\"].dt.year\n",
    "\n",
    "    df_por_dep = df.groupby([\"dependencia\", \"anio\"]).agg({\n",
    "                    'Sueldo Neto': ['sum', 'count', 'mean', 'min', 'max']\n",
    "                }).reset_index()\n",
    "    df_por_dep.columns = ['Tipo', 'anio', 'Suma_Total_sueldos',\n",
    "                            'Conteo_Empleados', 'Promedio_sueldo',\n",
    "                            'Salario_Minimo', 'Salario_Maximo']\n",
    "    \n",
    "    return df_por_dep\n",
    "\n",
    "\n",
    "def crear_diagrama_caja(nombre_archivo: str, columna: str,\n",
    "    funcion_agregacion: callable = pd.DataFrame.sum) -> None:\n",
    "    \"\"\"\n",
    "    Crea un diagrama de caja a partir de valores separados por comas.\n",
    "\n",
    "    Args:\n",
    "    - nombre_archivo (str): El nombre del archivo.\n",
    "    - columna (str): La columna para la cual crear el diagrama de caja.\n",
    "    - funcion_agregacion (callable): La función de agregación a usar.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(nombre_archivo)\n",
    "    df_por_tipo = df.groupby([columna, \"Fecha\"])[[\"Sueldo Neto\"]] \\\n",
    "                    .aggregate(funcion_agregacion)\n",
    "    df_por_tipo.boxplot(by=columna, figsize=(27, 18))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(f\"img/boxplot_{columna}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def graficar_por_dependencia(df: pd.DataFrame, dependencia: str) -> None:\n",
    "    \"\"\"\n",
    "    Crea gráficos de línea y de caja para una dependencia específica.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): La tabla con los datos.\n",
    "    - dependencia (str): La dependencia para la cual crear los gráficos.\n",
    "    \"\"\"\n",
    "    df_dep = df[df[\"dependencia\"] == dependencia]\n",
    "\n",
    "    df_dep.plot(y=[\"Sueldo Neto\"], title=f\"Línea de tiempo - {dependencia}\")\n",
    "    plt.savefig(f\"img/lt_{dependencia}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    df_dep.boxplot(column=[\"Sueldo Neto\"], by='dependencia')\n",
    "    plt.savefig(f\"img/bplt_{dependencia}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def graficar_por_dependencia_archivo(nombre_archivo: str) -> None:\n",
    "    \"\"\"\n",
    "    Crea gráficos de línea y de caja por dependencia a partir de valores\n",
    "    separados por comas.\n",
    "\n",
    "    Args:\n",
    "    - nombre_archivo (str): El nombre del archivo.\n",
    "    \"\"\"\n",
    "    df_completo = pd.read_csv(nombre_archivo)\n",
    "    os.makedirs('img', exist_ok=True)\n",
    "    df_por_dependencia = df_completo.groupby([\"dependencia\",\n",
    "                \"Fecha\"])[[\"Sueldo Neto\"]].agg('count').reset_index()\n",
    "    df_por_dependencia.set_index(\"Fecha\", inplace=True)\n",
    "\n",
    "    dependencias = df_por_dependencia[\"dependencia\"].unique()\n",
    "    for dependencia in dependencias:\n",
    "       plot_by_dep(df_por_dependencia, dependencia)\n",
    "\n",
    "\n",
    "    df_aux = df_completo.groupby([\"Fecha\", \"dependencia\"])[['Sueldo Neto']] \\\n",
    "                        .mean().unstack()\n",
    "    df_aux.plot(y='Sueldo Neto', legend=False, figsize=(32, 18))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('Fecha')\n",
    "    plt.ylabel('Sueldo Neto')\n",
    "    plt.savefig(\"img/promedio_sueldo_por_dependencia.png\")\n",
    "    plt.close()\n",
    "\n",
    "def realizar_anova(df: pd.DataFrame, formula_ols: str):\n",
    "    \"\"\"\n",
    "    Realiza un análisis de varianza una tabla dada.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): La tabla en la cual realizar el análisis.\n",
    "    - formula_ols (str): La fórmula para el modelo OLS.\n",
    "    \"\"\"\n",
    "    modelo = ols(formula_ols, data=df).fit()\n",
    "    tabla_anova = sm.stats.anova_lm(modelo, typ=2)\n",
    "\n",
    "    if tabla_anova[\"PR(>F)\"][0] < 0.005:\n",
    "        print(\"Hay diferencias significativas\")\n",
    "        print(tabla_anova)\n",
    "\n",
    "        # Prueba de Tukey\n",
    "        tukey = pairwise_tukeyhsd(df['GastoSalarios'], df['Tipo'])\n",
    "        print(tukey)\n",
    "    else:\n",
    "        print(\"No hay diferencias significativas\")\n",
    "\n",
    "def realizar_anova(nombre_archivo: str):\n",
    "    \"\"\"\n",
    "    Realiza un análisis de varianza para valores separados por comas.\n",
    "\n",
    "    Args:\n",
    "    - file_name (str): El nombre del archivo.\n",
    "    \"\"\"\n",
    "    df_completo = pd.read_csv(nombre_archivo)\n",
    "\n",
    "    df_por_tipo = df_completo.groupby([\"Tipo\", \"Fecha\"])[[\"Sueldo Neto\"]] \\\n",
    "                            .sum().reset_index()\n",
    "    \n",
    "    df_aux = df_por_tipo.rename(columns={\"Sueldo Neto\": \"GastoSalarios\"})\n",
    "    \n",
    "    tipos_interes = [\"ADMIN\", \"CENTRO\", \"OTRO\", \"HOSPITAL\", \"PREPARATORIA\"]\n",
    "    df_aux = df_aux[df_aux[\"Tipo\"].isin(tipos_interes)]\n",
    "\n",
    "    print(df_aux.head())\n",
    "    print(df_aux.columns)\n",
    "\n",
    "    realizar_anova(df_aux, \"GastoSalarios ~ Tipo\")\n",
    "\n",
    "def analizar_archivo(nombre_archivo: str) -> None:\n",
    "    \"\"\"\n",
    "    Realiza el análisis de valores separados por comas y muestra los resultados.\n",
    "\n",
    "    Args:\n",
    "    - nombre_archivo (str): El nombre del archivo a analizar.\n",
    "    \"\"\"\n",
    "    df_completo = pd.read_csv(nombre_archivo)\n",
    "    df_completo.columns = df_completo.columns.str.strip()  # Eliminar espacios adicionales\n",
    "    \n",
    "    mostrar_tabla(df_completo[[\"dependencia\", \"Tipo\"]].drop_duplicates().head(150))\n",
    "\n",
    "    df_por_dependencia = df_completo.groupby([\"dependencia\",\n",
    "                            \"Fecha\"])[[\"Sueldo Neto\"]].sum().reset_index()\n",
    "    df_por_dependencia.set_index(\"Fecha\", inplace=True)\n",
    "\n",
    "    for dependencia in df_por_dependencia[\"dependencia\"].unique():\n",
    "       graficar_por_dependencia(df_por_dependencia, dependencia)\n",
    "\n",
    "    df_aux = df_completo.groupby([\"Fecha\",\"dependencia\"])[['Sueldo Neto']] \\\n",
    "                        .mean().unstack()\n",
    "    df_aux.plot(y='Sueldo Neto', legend=False, figsize=(32,18))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(\"img/foo.png\")\n",
    "    plt.close()\n",
    "\n",
    "    df_por_dependencia.boxplot(by ='dependencia', figsize=(32,18))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(\"img/boxplot.png\")# , bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    df_por_tipo = df_completo.groupby([\"Tipo\",\n",
    "            \"Fecha\"])[[\"Sueldo Neto\"]].aggregate(pd.DataFrame.sum)# .count()\n",
    "    df_por_tipo.boxplot(by = 'Tipo', figsize=(18,9))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(\"img/boxplot_tipo.png\")\n",
    "    plt.close()\n",
    "\n",
    "    df_aux = df_por_tipo.reset_index().rename(columns={\"Sueldo Neto\": \"GastoSalarios\"})\n",
    "    print(df_aux.head())\n",
    "\n",
    "    realizar_anova(df_aux, \"GastoSalarios ~ Tipo\")\n",
    "\n",
    "def agregar_tipos(nombre_archivo: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crear una tabla con tipos a partir de valores separados por comas.\n",
    "\n",
    "    Args:\n",
    "    - filename (str): El nombre del archivo.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: La tabla con tipos.\n",
    "    \"\"\"\n",
    "    df_completo = pd.read_csv(nombre_archivo)\n",
    "    return agregar_tipos(df_completo)\n",
    "\n",
    "def mostrar_tipos_dependencias() -> None:\n",
    "    \"\"\"\n",
    "    Muestra los tipos de dependencias.\n",
    "    \"\"\"\n",
    "    df_completo = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    mostrar_tabla(df_completo[['dependencia', 'Tipo']] \\\n",
    "        .drop_duplicates().head(150))\n",
    "\n",
    "def show_salary_and_count_by_dependency_and_date():\n",
    "    \"\"\"\n",
    "    Muestra el salario y el conteo por dependencia y fecha\n",
    "    \"\"\"\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_complete.columns = df_complete.columns.str.strip()  # Eliminar espacios adicionales\n",
    "    \n",
    "    print(\"Columnas del DataFrame en show_salary_and_count_by_dependency_and_date:\", df_complete.columns)\n",
    "    \n",
    "    df_by_type = df_complete.groupby([\"dependencia\", \"Fecha\"]).agg({\n",
    "        'Sueldo Neto': ['sum', 'count', 'mean', 'max']\n",
    "    })\n",
    "    \n",
    "    # Imprimir la estructura del DataFrame\n",
    "    print(\"Estructura del DataFrame resultante del groupby y agg:\", df_by_type.head())\n",
    "    \n",
    "    # Asignar nombres de columnas\n",
    "    df_by_type.columns = ['Total_sueldos', 'Conteo_Empleado', 'Promedio_sueldo', 'Salario_Maximo']\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    \n",
    "    display_dataframe(df_by_type.head(150))\n",
    "\n",
    "\n",
    "def show_data_by_type_and_date():\n",
    "    \"\"\"\n",
    "    Muestra los datos por tipo y fecha\n",
    "    \"\"\"\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"])[[\"Sueldo Neto\"]].sum()\n",
    "    display_dataframe(df_by_type.head(150))\n",
    "\n",
    "def show_salary_and_count_by_type_and_date():\n",
    "    \"\"\"\n",
    "    Muestra el salario y el conteo por tipo y fecha.\n",
    "    \"\"\"\n",
    "    df_complete = pd.read_csv(\"csv/typed_uanl.csv\")\n",
    "    df_complete.columns = df_complete.columns.str.strip()  # Eliminar espacios adicionales\n",
    "    \n",
    "    print(\"Columnas del DataFrame en show_salary_and_count_by_type_and_date:\", df_complete.columns)\n",
    "    \n",
    "    df_by_type = df_complete.groupby([\"Tipo\", \"Fecha\"]).agg({\n",
    "        'Sueldo Neto': ['sum', 'count', 'mean', 'max']\n",
    "    })\n",
    "    \n",
    "    # Imprimir la estructura del DataFrame\n",
    "    print(\"Estructura del DataFrame resultante del groupby y agg:\", df_by_type.head())\n",
    "    \n",
    "    # Asignar nombres de columnas\n",
    "    df_by_type.columns = ['Total_sueldos', 'Conteo_Empleado', 'Promedio_sueldo', 'Salario_Maximo']\n",
    "    df_by_type.reset_index(inplace=True)\n",
    "    df_by_type.set_index(\"Fecha\", inplace=True)\n",
    "    \n",
    "    display_dataframe(df_by_type.head(150))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    typed_df = create_typed_df(\"csv/uanl.csv\")\n",
    "    display_dataframe(typed_df.head(50))\n",
    "    typed_df.to_csv(\"csv/typed_uanl.csv\", index=False)\n",
    "\n",
    "    analyzed_df = analyze_by_department(typed_df)\n",
    "    analyzed_df.to_csv(\"csv/analyzed_uanl.csv\", index=False)\n",
    "\n",
    "    mostrar_tipos_dependencias()\n",
    "\n",
    "    # show_data_by_type_and_date()\n",
    "\n",
    "    # show_salary_and_count_by_type_and_date()\n",
    "\n",
    "    # show_salary_and_count_by_dependency_and_date()\n",
    "\n",
    "    analizar_archivo(\"csv/typed_uanl.csv\")\n",
    "\n",
    "    crear_diagrama_caja(\"csv/typed_uanl.csv\", 'Tipo', pd.DataFrame.sum)\n",
    "    #\"Tipo\")\n",
    "    \n",
    "    # create_plot_por_dependencia(\"csv/typed_uanl.csv\")\n",
    "    \n",
    "    # anova_1(\"csv/typed_uanl.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(file_name: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_name)\n",
    "    df[\"hab_x_km2\"] = df[\"poblacion_2020\"] / df[\"area_km2\"]\n",
    "    df[\"hab_x_mi\"] = df[\"poblacion_2020\"] / df[\"area_mi\"]\n",
    "    print(sum(df[\"poblacion_2020\"]))\n",
    "    return df\n",
    "\n",
    "df = analysis(\"csv/estados_limpio.csv\")\n",
    "display_dataframe(df.head())\n",
    "display_dataframe(df.describe())\n",
    "print(df[\"poblacion_2020\"].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
